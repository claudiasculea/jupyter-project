{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    " Bla bla bla\n",
    " \n",
    " ## 1. Libraries\n",
    " \n",
    "We are importing all the required libraries for the project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl #plot package\n",
    "import pandas as pd #powerful dataframe package\n",
    "import numpy as np # math package\n",
    "import os #file management package\n",
    "import sqlite3 # Database management package\n",
    "import requests #For downloading files\n",
    "from zipfile import ZipFile \n",
    "import re # for filtering text\n",
    "import numpy as np # For pretty printing\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation\n",
    "\n",
    "In this step we are setting up data to be analysed.\n",
    "\n",
    "### 2.1 Directory management \n",
    "\n",
    "We are creating a directory named data in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/jovyan/data already exists\n",
      "Changing directory to /home/jovyan/data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We check if we are in the data folder \n",
    "current_dir=os.getcwd()\n",
    "if 'data' in current_dir:\n",
    "    os.chdir('..')\n",
    "\n",
    "# We are setting the home directory to the Jupyter Root directory\n",
    "HOME_DIR=os.getcwd()\n",
    "\n",
    "# We are saving the location of the data directory                       \n",
    "DATA_DIR=HOME_DIR+'/data'\n",
    "\n",
    "# We check if the directory exists, if not,                        \n",
    "try:\n",
    "    os.makedirs(DATA_DIR)\n",
    "except FileExistsError :\n",
    "        print(\"Directory {} already exists\".format(DATA_DIR))\n",
    "os.chdir(DATA_DIR)\n",
    "print(\"Changing directory to {}\".format(DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Database setup\n",
    "\n",
    "We are setting up a database in order to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating or connecting to the data sqlite db and setting the cursor there\n",
    "\n",
    "database_connection = sqlite3.connect('ImportedData.db')\n",
    "database_cursor = database_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a table that traks downloaded files so we don't have to import them again\n",
    "\n",
    "database_cursor.execute(\"CREATE TABLE IF NOT EXISTS file_data(file_name TEXT UNIQUE)\")\n",
    "database_connection.commit()\n",
    "pd.read_sql_query(\"Select * from file_data\",database_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Querying the Citibike data \n",
    "\n",
    "We are checking the data available on the citibike website. This is hosted on Amazon AwS in the tripdata Bucket.\n",
    "\n",
    "What we do is we fetch the XML from s3, we parse it for files that are marked down inbetween `<Key>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found the following files on S3 \n",
      "201306-citibike-tripdata.zip\n",
      "201307-201402-citibike-tripdata.zip\n",
      "201307-citibike-tripdata.zip\n",
      "201308-citibike-tripdata.zip\n",
      "201309-citibike-tripdata.zip\n",
      "201310-citibike-tripdata.zip\n",
      "201311-citibike-tripdata.zip\n",
      "201312-citibike-tripdata.zip\n",
      "201401-citibike-tripdata.zip\n",
      "201402-citibike-tripdata.zip\n",
      "201403-citibike-tripdata.zip\n",
      "201404-citibike-tripdata.zip\n",
      "201405-citibike-tripdata.zip\n",
      "201406-citibike-tripdata.zip\n",
      "201407-citibike-tripdata.zip\n",
      "201408-citibike-tripdata.zip\n",
      "201409-citibike-tripdata.zip\n",
      "201410-citibike-tripdata.zip\n",
      "201411-citibike-tripdata.zip\n",
      "201412-citibike-tripdata.zip\n",
      "201501-citibike-tripdata.zip\n",
      "201502-citibike-tripdata.zip\n",
      "201503-citibike-tripdata.zip\n",
      "201504-citibike-tripdata.zip\n",
      "201505-citibike-tripdata.zip\n",
      "201506-citibike-tripdata.zip\n",
      "201507-citibike-tripdata.zip\n",
      "201508-citibike-tripdata.zip\n",
      "201509-citibike-tripdata.zip\n",
      "201510-citibike-tripdata.zip\n",
      "201511-citibike-tripdata.zip\n",
      "201512-citibike-tripdata.zip\n",
      "201601-citibike-tripdata.zip\n",
      "201602-citibike-tripdata.zip\n",
      "201603-citibike-tripdata.zip\n",
      "201604-citibike-tripdata.zip\n",
      "201605-citibike-tripdata.zip\n",
      "201606-citibike-tripdata.zip\n",
      "201607-citibike-tripdata.zip\n",
      "201608-citibike-tripdata.zip\n",
      "201609-citibike-tripdata.zip\n",
      "201610-citibike-tripdata.zip\n",
      "201611-citibike-tripdata.zip\n",
      "201612-citibike-tripdata.zip\n",
      "201701-citibike-tripdata.csv.zip\n",
      "201702-citibike-tripdata.csv.zip\n",
      "201703-citibike-tripdata.csv.zip\n",
      "201704-citibike-tripdata.csv.zip\n",
      "201705-citibike-tripdata.csv.zip\n",
      "201706-citibike-tripdata.csv.zip\n",
      "201707-citibike-tripdata.csv.zip\n",
      "201708-citibike-tripdata.csv.zip\n",
      "201709-citibike-tripdata.csv.zip\n",
      "201710-citibike-tripdata.csv.zip\n",
      "201711-citibike-tripdata.csv.zip\n",
      "201712-citibike-tripdata.csv.zip\n",
      "201801-citibike-tripdata.csv.zip\n",
      "201802-citibike-tripdata.csv.zip\n",
      "201803-citibike-tripdata.csv.zip\n",
      "201804-citibike-tripdata.csv.zip\n",
      "201805-citibike-tripdata.csv.zip\n",
      "201806-citibike-tripdata.csv.zip\n",
      "201807-citibike-tripdata.csv.zip\n",
      "201808-citibike-tripdata.csv.zip\n",
      "201809-citibike-tripdata.csv.zip\n",
      "201810-citibike-tripdata.csv.zip\n",
      "201811-citibike-tripdata.csv.zip\n",
      "201812-citibike-tripdata.csv.zip\n",
      "201901-citibike-tripdata.csv.zip\n",
      "201902-citibike-tripdata.csv.zip\n",
      "201903-citibike-tripdata.csv.zip\n",
      "201904-citibike-tripdata.csv.zip\n",
      "201905-citibike-tripdata.csv.zip\n",
      "201906-citibike-tripdata.csv.zip\n",
      "201907-citibike-tripdata.csv.zip\n",
      "201908-citibike-tripdata.csv.zip\n",
      "201909-citibike-tripdata.csv.zip\n",
      "201910-citibike-tripdata.csv.zip\n",
      "JC-201509-citibike-tripdata.csv.zip\n",
      "JC-201510-citibike-tripdata.csv.zip\n",
      "JC-201511-citibike-tripdata.csv.zip\n",
      "JC-201512-citibike-tripdata.csv.zip\n",
      "JC-201601-citibike-tripdata.csv.zip\n",
      "JC-201602-citibike-tripdata.csv.zip\n",
      "JC-201603-citibike-tripdata.csv.zip\n",
      "JC-201604-citibike-tripdata.csv.zip\n",
      "JC-201605-citibike-tripdata.csv.zip\n",
      "JC-201606-citibike-tripdata.csv.zip\n",
      "JC-201607-citibike-tripdata.csv.zip\n",
      "JC-201608-citibike-tripdata.csv.zip\n",
      "JC-201609-citibike-tripdata.csv.zip\n",
      "JC-201610-citibike-tripdata.csv.zip\n",
      "JC-201611-citibike-tripdata.csv.zip\n",
      "JC-201612-citibike-tripdata.csv.zip\n",
      "JC-201701-citibike-tripdata.csv.zip\n",
      "JC-201702-citibike-tripdata.csv.zip\n",
      "JC-201703-citibike-tripdata.csv.zip\n",
      "JC-201704-citibike-tripdata.csv.zip\n",
      "JC-201705-citibike-tripdata.csv.zip\n",
      "JC-201706-citibike-tripdata.csv.zip\n",
      "JC-201707-citibike-tripdata.csv.zip\n",
      "JC-201708 citibike-tripdata.csv.zip\n",
      "JC-201709-citibike-tripdata.csv.zip\n",
      "JC-201710-citibike-tripdata.csv.zip\n",
      "JC-201711-citibike-tripdata.csv.zip\n",
      "JC-201712-citibike-tripdata.csv.zip\n",
      "JC-201801-citibike-tripdata.csv.zip\n",
      "JC-201802-citibike-tripdata.csv.zip\n",
      "JC-201803-citibike-tripdata.csv.zip\n",
      "JC-201804-citibike-tripdata.csv.zip\n",
      "JC-201805-citibike-tripdata.csv.zip\n",
      "JC-201806-citibike-tripdata.csv.zip\n",
      "JC-201807-citibike-tripdata.csv.zip\n",
      "JC-201808-citibike-tripdata.csv.zip\n",
      "JC-201809-citibike-tripdata.csv.zip\n",
      "JC-201810-citibike-tripdata.csv.zip\n",
      "JC-201811-citibike-tripdata.csv.zip\n",
      "JC-201812-citibike-tripdata.csv.zip\n",
      "JC-201901-citibike-tripdata.csv.zip\n",
      "JC-201902-citibike-tripdata.csv.zip\n",
      "JC-201903-citibike-tripdata.csv.zip\n",
      "JC-201904-citibike-tripdata.csv.zip\n",
      "JC-201905-citibike-tripdata.csv.zip\n",
      "JC-201906-citibike-tripdata.csv.zip\n",
      "JC-201907-citibike-tripdata.csv.zip\n",
      "JC-201908-citibike-tripdata.csv.zip\n",
      "JC-201909-citibike-tripdata.csv.zip\n",
      "JC-201910-citibike-tripdata.csv.zip\n"
     ]
    }
   ],
   "source": [
    "# Fetching a file list of all available files on the Citybike data server\n",
    "\n",
    "s3_url = \"https://s3.amazonaws.com/tripdata\"\n",
    "\n",
    "s3_xml_file = requests.get(s3_url).text\n",
    "\n",
    "files_on_s3 = re.findall (r'<Key>(.*?zip)</Key>', s3_xml_file)\n",
    "\n",
    "print ('We have found the following files on S3 ')\n",
    "\n",
    "print (\"\\n\".join(files_on_s3))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Setup methods for file management\n",
    "\n",
    "Here we define all the methods we will use when adding data into the database. We have 5 methods one for downloading, one for unzipping, one for checking if the file exists in the database, one for adding the file in the database, and a cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(filename):\n",
    "    delete_files_ending_with('zip')\n",
    "    download_url = s3_url + '/' + filename\n",
    "    print(\"Downloading file: \" + download_url)\n",
    "    file_data = requests.get(download_url)\n",
    "    open(filename, 'wb').write(file_data.content)\n",
    "    \n",
    "def unzipping_file(filename):\n",
    "    file = ZipFile(filename,'r')\n",
    "    print(\"Extracting... \")\n",
    "    file.extractall()\n",
    "    unzipped_file = glob.glob('*.csv')\n",
    "    print(\"Extracted \" + unzipped_file[0] + \" from \" + filename + \". Deleting archive to save space...\")\n",
    "    delete_files_ending_with('zip')\n",
    "    return unzipped_file[0]\n",
    "\n",
    "def delete_files_ending_with(extension):\n",
    "    for file in glob.glob('*'+ extension):\n",
    "            os.remove(file)\n",
    "\n",
    "def file_has_been_added_to_the_database(filename):\n",
    "    database_cursor.execute(\"SELECT file_name FROM file_data WHERE file_name = ?\",(filename,))\n",
    "    if database_cursor.fetchone() is None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def save_file_name_into_database(filename):\n",
    "    database_cursor.execute(\"INSERT INTO file_data (file_name) VALUES(?)\",(filename,))\n",
    "    database_connection.commit()\n",
    "\n",
    "def import_data_from_file_into_database(filename):\n",
    "    file_data = pd.read_csv(extracted_file, names=['tripduration','starttime','stoptime','start station id','start station name',\n",
    "                                      'start station latitude', 'start station longitude', 'end station id',\n",
    "                                      'end station name', 'end station latitude', 'end station longitude', 'bikeid',\n",
    "                                      'usertype', 'birth year', 'gender'], header=None, skiprows=[0])\n",
    "    file_data.to_sql('trip_data', database_connection, if_exists='replace', index = False )\n",
    "    database_connection.commit()\n",
    "    print(\"Adding data from \"+filename+\" to the database\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We are scanning our data directory and saving the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file: https://s3.amazonaws.com/tripdata/201306-citibike-tripdata.zip\n",
      "Extracting... \n",
      "Extracted 201306-citibike-tripdata.csv from 201306-citibike-tripdata.zip. Deleting archive to save space...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:2712: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  method=method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data from %s to the database ('201306-citibike-tripdata.csv',)\n",
      "Downloading file: https://s3.amazonaws.com/tripdata/201307-201402-citibike-tripdata.zip\n",
      "Extracting... \n",
      "Extracted 2013-09 - Citi Bike trip data.csv from 201307-201402-citibike-tripdata.zip. Deleting archive to save space...\n",
      "Adding data from %s to the database ('2013-09 - Citi Bike trip data.csv',)\n",
      "Downloading file: https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip\n",
      "Extracting... \n",
      "Extracted 2013-07 - Citi Bike trip data.csv from 201307-citibike-tripdata.zip. Deleting archive to save space...\n",
      "Adding data from %s to the database ('2013-07 - Citi Bike trip data.csv',)\n",
      "Downloading file: https://s3.amazonaws.com/tripdata/201308-citibike-tripdata.zip\n",
      "Extracting... \n",
      "Extracted 2013-08 - Citi Bike trip data.csv from 201308-citibike-tripdata.zip. Deleting archive to save space...\n",
      "Adding data from %s to the database ('2013-08 - Citi Bike trip data.csv',)\n",
      "Downloading file: https://s3.amazonaws.com/tripdata/201309-citibike-tripdata.zip\n",
      "Extracting... \n",
      "Extracted 2013-09 - Citi Bike trip data.csv from 201309-citibike-tripdata.zip. Deleting archive to save space...\n"
     ]
    }
   ],
   "source": [
    "file_count = 0\n",
    "\n",
    "for file in files_on_s3:\n",
    "    if not file_has_been_added_to_the_database(file):\n",
    "        try:\n",
    "            download_file(file)\n",
    "            extracted_file = unzipping_file(file)\n",
    "            save_file_name_into_database(file)\n",
    "            import_data_from_file_into_database(extracted_file)\n",
    "            delete_files_ending_with('csv')\n",
    "            file_count += 1\n",
    "        except XLRDError:\n",
    "            print(\"Close any open files and try again\")\n",
    "\n",
    "print('We imported '+files_count+' files into imported_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_cursor.execute(\"SELECT * FROM trip_data limit 5\")\n",
    "print( database_cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_cursor.execute(\"SELECT bikeid, SUM(stoptime - starttime),  FROM trip_data\")\n",
    "print( database_cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
