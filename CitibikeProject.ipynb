{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Bla bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We are importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl #plot package\n",
    "import pandas as pd #powerful dataframe package\n",
    "import numpy as np # math package\n",
    "import os #file management package\n",
    "import sqlite3\n",
    "\n",
    "import datetime, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We are setting up our data location and changing the workspace directory to that directory in order to import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"./data\"\n",
    "\n",
    "try:\n",
    "    os.chdir(DATA_DIR)\n",
    "except:\n",
    "    print (\"No data directory. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We are scanning our data directory and saving the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The foloowing files were found:\n",
      "\n",
      "2013-07 - Citi Bike trip data.csv\n",
      "2013-08 - Citi Bike trip data.csv\n",
      "2013-09 - Citi Bike trip data.csv\n",
      "2013-10 - Citi Bike trip data.csv\n",
      "2013-11 - Citi Bike trip data.csv\n",
      "2013-12 - Citi Bike trip data.csv\n",
      "201306-citibike-tripdata.csv\n",
      "2014-01 - Citi Bike trip data.csv\n",
      "2014-02 - Citi Bike trip data.csv\n",
      "2014-03 - Citi Bike trip data.csv\n",
      "2014-04 - Citi Bike trip data.csv\n",
      "2014-05 - Citi Bike trip data.csv\n",
      "2014-06 - Citi Bike trip data.csv\n",
      "2014-07 - Citi Bike trip data.csv\n",
      "2014-08 - Citi Bike trip data.csv\n",
      "201409-citibike-tripdata.csv\n",
      "201410-citibike-tripdata.csv\n",
      "201411-citibike-tripdata.csv\n",
      "201412-citibike-tripdata.csv\n",
      "201501-citibike-tripdata.csv\n",
      "201502-citibike-tripdata.csv\n",
      "201503-citibike-tripdata.csv\n",
      "201504-citibike-tripdata.csv\n",
      "201505-citibike-tripdata.csv\n",
      "201506-citibike-tripdata.csv\n",
      "201507-citibike-tripdata.csv\n",
      "201508-citibike-tripdata.csv\n",
      "201509-citibike-tripdata.csv\n",
      "201510-citibike-tripdata.csv\n",
      "201511-citibike-tripdata.csv\n",
      "201512-citibike-tripdata.csv\n",
      "201601-citibike-tripdata.csv\n",
      "201602-citibike-tripdata.csv\n",
      "201603-citibike-tripdata.csv\n",
      "201604-citibike-tripdata.csv\n",
      "201605-citibike-tripdata.csv\n",
      "201606-citibike-tripdata.csv\n",
      "201607-citibike-tripdata.csv\n",
      "201608-citibike-tripdata.csv\n",
      "201609-citibike-tripdata.csv\n",
      "201610-citibike-tripdata.csv\n",
      "201611-citibike-tripdata.csv\n",
      "201612-citibike-tripdata.csv\n",
      "201701-citibike-tripdata.csv\n",
      "201702-citibike-tripdata.csv\n",
      "201703-citibike-tripdata.csv\n",
      "201704-citibike-tripdata.csv\n",
      "201705-citibike-tripdata.csv\n",
      "201706-citibike-tripdata.csv\n",
      "201707-citibike-tripdata.csv\n",
      "201708-citibike-tripdata.csv\n",
      "201709-citibike-tripdata.csv\n",
      "201710-citibike-tripdata.csv\n",
      "201711-citibike-tripdata.csv\n",
      "201712-citibike-tripdata.csv\n",
      "201801-citibike-tripdata.csv\n",
      "201802-citibike-tripdata.csv\n",
      "201803-citibike-tripdata.csv\n",
      "201804-citibike-tripdata.csv\n",
      "201805-citibike-tripdata.csv\n",
      "201806-citibike-tripdata.csv\n",
      "201807-citibike-tripdata.csv\n",
      "201808-citibike-tripdata.csv\n",
      "201809-citibike-tripdata.csv\n",
      "201810-citibike-tripdata.csv\n",
      "201811-citibike-tripdata.csv\n",
      "201812-citibike-tripdata.csv\n",
      "201901-citibike-tripdata.csv\n",
      "201902-citibike-tripdata.csv\n",
      "201903-citibike-tripdata.csv\n",
      "201904-citibike-tripdata.csv\n",
      "201905-citibike-tripdata.csv\n",
      "201906-citibike-tripdata.csv\n",
      "201907-citibike-tripdata.csv\n",
      "201908-citibike-tripdata.csv\n",
      "201909-citibike-tripdata.csv\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob((DATA_DIR + \"/*.csv\").split(\"/\")[-1])\n",
    "files.sort()\n",
    "print('The foloowing files were found:\\n')\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection = sqlite3.connect('ImportedData.db')\n",
    "database_cursor = database_connection.cursor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We are preparing the base data structure for importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tripduration, starttime, stoptime, start station id, start station name, start station latitude, start station longitude, end station id, end station name, end station latitude, end station longitude, bikeid, usertype, birth year, gender]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_data = pd.DataFrame(columns=['tripduration',\n",
    "'starttime',\n",
    "'stoptime',\n",
    "'start station id',\n",
    "'start station name',\n",
    "'start station latitude',\n",
    "'start station longitude',\n",
    "'end station id',\n",
    "'end station name',\n",
    "'end station latitude',\n",
    "'end station longitude',\n",
    "'bikeid',\n",
    "'usertype',\n",
    "'birth year',\n",
    "'gender'])\n",
    "imported_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. We are streaming data from each file into our imported data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I tried to concatenate the csv files into ine file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 2013-07 - Citi Bike trip data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:2712: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  method=method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 2013-08 - Citi Bike trip data.csv\n",
      "Parsing 2013-09 - Citi Bike trip data.csv\n",
      "Parsing 2013-10 - Citi Bike trip data.csv\n",
      "Parsing 2013-11 - Citi Bike trip data.csv\n",
      "Parsing 2013-12 - Citi Bike trip data.csv\n",
      "Parsing 201306-citibike-tripdata.csv\n",
      "Parsing 2014-01 - Citi Bike trip data.csv\n",
      "Parsing 2014-02 - Citi Bike trip data.csv\n",
      "Parsing 2014-03 - Citi Bike trip data.csv\n",
      "Parsing 2014-04 - Citi Bike trip data.csv\n",
      "Parsing 2014-05 - Citi Bike trip data.csv\n",
      "Parsing 2014-06 - Citi Bike trip data.csv\n",
      "Parsing 2014-07 - Citi Bike trip data.csv\n",
      "Parsing 2014-08 - Citi Bike trip data.csv\n",
      "Parsing 201409-citibike-tripdata.csv\n",
      "Parsing 201410-citibike-tripdata.csv\n",
      "Parsing 201411-citibike-tripdata.csv\n",
      "Parsing 201412-citibike-tripdata.csv\n",
      "Parsing 201501-citibike-tripdata.csv\n",
      "Parsing 201502-citibike-tripdata.csv\n",
      "Parsing 201503-citibike-tripdata.csv\n",
      "Parsing 201504-citibike-tripdata.csv\n",
      "Parsing 201505-citibike-tripdata.csv\n",
      "Parsing 201506-citibike-tripdata.csv\n",
      "Parsing 201507-citibike-tripdata.csv\n",
      "Parsing 201508-citibike-tripdata.csv\n",
      "Parsing 201509-citibike-tripdata.csv\n",
      "Parsing 201510-citibike-tripdata.csv\n",
      "Parsing 201511-citibike-tripdata.csv\n",
      "Parsing 201512-citibike-tripdata.csv\n",
      "Parsing 201601-citibike-tripdata.csv\n",
      "Parsing 201602-citibike-tripdata.csv\n",
      "Parsing 201603-citibike-tripdata.csv\n",
      "Parsing 201604-citibike-tripdata.csv\n",
      "Parsing 201605-citibike-tripdata.csv\n",
      "Parsing 201606-citibike-tripdata.csv\n",
      "Parsing 201607-citibike-tripdata.csv\n",
      "Parsing 201608-citibike-tripdata.csv\n",
      "Parsing 201609-citibike-tripdata.csv\n",
      "Parsing 201610-citibike-tripdata.csv\n",
      "Parsing 201611-citibike-tripdata.csv\n",
      "Parsing 201612-citibike-tripdata.csv\n",
      "Parsing 201701-citibike-tripdata.csv\n",
      "Parsing 201702-citibike-tripdata.csv\n",
      "Parsing 201703-citibike-tripdata.csv\n",
      "Parsing 201704-citibike-tripdata.csv\n",
      "Parsing 201705-citibike-tripdata.csv\n",
      "Parsing 201706-citibike-tripdata.csv\n",
      "Parsing 201707-citibike-tripdata.csv\n",
      "Parsing 201708-citibike-tripdata.csv\n",
      "Parsing 201709-citibike-tripdata.csv\n",
      "Parsing 201710-citibike-tripdata.csv\n",
      "Parsing 201711-citibike-tripdata.csv\n",
      "Parsing 201712-citibike-tripdata.csv\n",
      "Parsing 201801-citibike-tripdata.csv\n",
      "Parsing 201802-citibike-tripdata.csv\n",
      "Parsing 201803-citibike-tripdata.csv\n",
      "Parsing 201804-citibike-tripdata.csv\n",
      "Parsing 201805-citibike-tripdata.csv\n",
      "Parsing 201806-citibike-tripdata.csv\n",
      "Parsing 201807-citibike-tripdata.csv\n",
      "Parsing 201808-citibike-tripdata.csv\n",
      "Parsing 201809-citibike-tripdata.csv\n",
      "Parsing 201810-citibike-tripdata.csv\n",
      "Parsing 201811-citibike-tripdata.csv\n",
      "Parsing 201812-citibike-tripdata.csv\n",
      "Parsing 201901-citibike-tripdata.csv\n",
      "Parsing 201902-citibike-tripdata.csv\n",
      "Parsing 201903-citibike-tripdata.csv\n",
      "Parsing 201904-citibike-tripdata.csv\n",
      "Parsing 201905-citibike-tripdata.csv\n",
      "Parsing 201906-citibike-tripdata.csv\n",
      "Parsing 201907-citibike-tripdata.csv\n",
      "Parsing 201908-citibike-tripdata.csv\n",
      "Parsing 201909-citibike-tripdata.csv\n",
      "We imported {file_count} files into imported_data\n"
     ]
    }
   ],
   "source": [
    "file_count = 0\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        # We are importing each file at a time and appending it to the big imported_data \n",
    "        print(f\"Parsing {file}\")\n",
    "        file_data = pd.read_csv(file, names=['tripduration','starttime','stoptime','start station id','start station name',\n",
    "                                      'start station latitude', 'start station longitude', 'end station id',\n",
    "                                      'end station name', 'end station latitude', 'end station longitude', 'bikeid',\n",
    "                                      'usertype', 'birth year', 'gender'], header=None, skiprows=[0])\n",
    "        file_data.to_sql('trip_data', database_connection, if_exists='replace', index = False )\n",
    "        \n",
    "        # imported_data = imported_data.append(file_data, ignore_index=True, sort=False)\n",
    "        file_count+=1\n",
    "    except XLRDError:\n",
    "        print(\"Close any open files and try again\")\n",
    "\n",
    "print('We imported {file_count} files into imported_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for file in files:\n",
    "#        print(DATA_DIR+file)\n",
    "#        df = pd.concat(DATA_DIR+\"/\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(327, '2019-09-01 00:00:01.9580', '2019-09-01 00:05:29.3410', 3733, 'Avenue C & E 18 St', 40.730563000000004, -73.973984, 504, '1 Ave & E 16 St', 40.73221853, -73.98165557, 39213, 'Subscriber', 1968, 1), (1145, '2019-09-01 00:00:04.1430', '2019-09-01 00:19:09.8360', 3329, 'Degraw St & Smith St', 40.6829151, -73.99318208, 270, 'Adelphi St & Myrtle Ave', 40.69308257, -73.97178913, 21257, 'Customer', 1969, 0), (1293, '2019-09-01 00:00:07.3090', '2019-09-01 00:21:40.7580', 3168, 'Central Park West & W 85 St', 40.78472675, -73.96961715, 423, 'W 54 St & 9 Ave', 40.76584941, -73.98690506, 15242, 'Customer', 1969, 0), (1753, '2019-09-01 00:00:08.0640', '2019-09-01 00:29:21.5040', 3299, 'E 98 St & Park Ave', 40.788129999999995, -73.95206, 3160, 'Central Park West & W 76 St', 40.77896784, -73.97374737, 38760, 'Subscriber', 1990, 1), (613, '2019-09-01 00:00:12.8510', '2019-09-01 00:10:26.1850', 486, 'Broadway & W 29 St', 40.7462009, -73.98855723, 478, '11 Ave & W 41 St', 40.76030096, -73.99884222, 32094, 'Subscriber', 1992, 1)]\n"
     ]
    }
   ],
   "source": [
    "database_cursor.execute(\"SELECT * FROM trip_data limit 5\")\n",
    "print( database_cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32303, '2019-09-01 00:00:01.9580', '2019-10-11 15:16:53.3070')]\n"
     ]
    }
   ],
   "source": [
    "database_cursor.execute(\"SELECT DISTINCT bikeid,SUM(maxTIME)  FROM trip_data\")\n",
    "print( database_cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
